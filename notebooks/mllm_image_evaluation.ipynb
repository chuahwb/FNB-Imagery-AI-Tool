{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chuahwb/FNB-Imagery-AI-Tool/blob/main/notebooks/mllm_image_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "IPython Notebook for Phase 2: Evaluating Multimodal LLMs for F&B Image Recreation\n",
        "\n",
        "This notebook connects to OpenRouter, processes local images, sends them with\n",
        "prompts to selected multimodal LLMs, retrieves structured descriptions\n",
        "using the 'instructor' library, tracks token usage, and estimates costs.\n",
        "\"\"\"\n",
        "\n",
        "# @title Setup: Install Libraries and Import Modules\n",
        "# Install necessary libraries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1cBTxvrwSv3P",
        "outputId": "cf665f68-6f1d-4d4a-8498-89c6fd1feafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nIPython Notebook for Phase 2: Evaluating Multimodal LLMs for F&B Image Recreation\\n\\nThis notebook connects to OpenRouter, processes local images, sends them with\\nprompts to selected multimodal LLMs, retrieves structured descriptions\\nusing the 'instructor' library, tracks token usage, and estimates costs.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor openai python-dotenv pillow pandas tqdm Jinja2 openpyxl xlsxwriter -q # Added Jinja2 for HTML templating"
      ],
      "metadata": {
        "id": "8vhbXuebS2aD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10669a91-c19b-412f-da1e-7c186c22ee93"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/169.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/345.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "import instructor\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel, Field, field_validator, PrivateAttr\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from typing import List, Optional, Tuple, Dict, Any\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "import time\n",
        "import datetime\n",
        "import re\n",
        "import traceback # For detailed error logging\n",
        "from jinja2 import Environment, FileSystemLoader, select_autoescape # For HTML report\n",
        "import html # For escaping text in HTML"
      ],
      "metadata": {
        "id": "p6UbXWCHS5ja"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "def load_images_from_drive(dataset_path):\n",
        "  \"\"\"Loads images from Google Drive and returns a list of tuples.\n",
        "\n",
        "  Args:\n",
        "    dataset_path: The path to the dataset folder in Google Drive.\n",
        "\n",
        "  Returns:\n",
        "    A list of tuples, where each tuple contains the image ID, path, and category.\n",
        "  \"\"\"\n",
        "\n",
        "  drive.mount('/content/drive')\n",
        "  images_data = []\n",
        "  category_counts = {}\n",
        "\n",
        "  for category in os.listdir(dataset_path):\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    if os.path.isdir(category_path):\n",
        "      for image_file in os.listdir(category_path):\n",
        "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "          image_id = os.path.splitext(image_file)[0]  # Use filename as ID\n",
        "          image_path = os.path.join(category_path, image_file)\n",
        "          images_data.append((image_id, image_path, category))\n",
        "          category_counts[category] = category_counts.get(category, 0) + 1\n",
        "\n",
        "  total_images = len(images_data)\n",
        "  print(f\"Total images loaded: {total_images}\")\n",
        "  print(\"Images loaded per category:\")\n",
        "  for category, count in category_counts.items():\n",
        "    print(f\"- {category}: {count}\")\n",
        "\n",
        "  return images_data\n",
        "\n",
        "# Set the path to your dataset folder in Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image'\n",
        "\n",
        "# Load the images\n",
        "IMAGES_TO_PROCESS = load_images_from_drive(dataset_path)\n",
        "\n",
        "# Now IMAGES_TO_PROCESS contains your list of tuples\n",
        "# You can use it in your existing code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-Ve8mZAYDs6",
        "outputId": "a335877d-12de-4a2e-9f49-37fab6a5cc5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Total images loaded: 24\n",
            "Images loaded per category:\n",
            "- Product Shot: 13\n",
            "- Menu Displays: 9\n",
            "- Location Ambience Shots: 1\n",
            "- Event Promotions: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configure API Key and OpenRouter Client\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# Set your OpenRouter API key.\n",
        "# Option 1: Create a .env file in the same directory as this notebook\n",
        "#           with the line: OPENROUTER_API_KEY=\"your-key-here\"\n",
        "# Option 2: Set it as an environment variable in your system.\n",
        "# Option 3: Replace os.getenv(\"OPENROUTER_API_KEY\") below with your actual key string\n",
        "#           (less secure, not recommended for shared notebooks).\n",
        "dotenv_path = \"/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/colab_secrets/.env\"\n",
        "\n",
        "if os.path.exists(dotenv_path):\n",
        "    load_dotenv(dotenv_path=dotenv_path)\n",
        "    print(f\"Loaded .env file from path: {dotenv_path}\")\n",
        "else:\n",
        "    print(f\"Error: .env file not found at path: {dotenv_path}\")\n",
        "\n",
        "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY_1\")\n",
        "\n",
        "if not OPENROUTER_API_KEY:\n",
        "    print(\"⚠️ OpenRouter API Key not found.\")\n",
        "    # OPENROUTER_API_KEY = input(\"Enter your OpenRouter API Key: \")\n",
        "if not GEMINI_API_KEY:\n",
        "    print(\"⚠️ Gemini API Key not found.\")\n",
        "    # GEMINI_API_KEY = input(\"Enter your Gemini API Key: \")\n",
        "\n",
        "# Select LLM service provider\n",
        "LLM_SERVICE_PROVIDER = \"OpenRouter\" # or \"Gemini\" or \"openai\" or \"OpenRouter\"\n",
        "if LLM_SERVICE_PROVIDER == \"OpenRouter\":\n",
        "  CLIENT_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "  CLIENT_API_KEY = OPENROUTER_API_KEY\n",
        "elif LLM_SERVICE_PROVIDER == \"Gemini\":\n",
        "  CLIENT_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "  CLIENT_API_KEY = GEMINI_API_KEY\n",
        "\n",
        "\n",
        "# Configure the Instructor client to use OpenRouter\n",
        "# Patch the OpenAI client to add structured response capabilities\n",
        "# Store the original unpatched client for accessing raw response data if needed\n",
        "# Note: Instructor v1+ modifies the client in place. We access usage from the returned pydantic model's _raw_response attribute.\n",
        "client = instructor.patch(\n",
        "    OpenAI(\n",
        "        base_url=CLIENT_BASE_URL,\n",
        "        api_key=CLIENT_API_KEY,\n",
        "        default_headers={ # Optional, but good practice for OpenRouter\n",
        "            \"HTTP-Referer\": \"http://localhost:8888\", # Replace with your app URL if deployed\n",
        "            \"X-Title\": \"F&B Image Eval\", # Replace with your app name\n",
        "        },\n",
        "        timeout=600 # Increase timeout for potentially long image processing\n",
        "    ),\n",
        "    mode=instructor.Mode.MD_JSON # Use Markdown JSON mode for better compatibility\n",
        ")\n",
        "\n",
        "print(f\"✅ OpenAI client patched with Instructor and configured for {LLM_SERVICE_PROVIDER}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2OYS7fGTxTm",
        "outputId": "1ab12d81-0783-4059-b234-c33123be816f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded .env file from path: /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/colab_secrets/.env\n",
            "✅ OpenAI client patched with Instructor and configured for OpenRouter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Pydantic Model for Structured Description\n",
        "# This model mirrors the 8 points requested in the prompts\n",
        "\n",
        "class FnbImageDescription(BaseModel):\n",
        "    \"\"\"Structured description of an F&B social media image.\"\"\"\n",
        "    primary_subject: str = Field(..., description=\"Detailed description of the main food, drink, person, or element, including ingredients, preparation, presentation, and actions.\")\n",
        "    composition_framing: str = Field(..., description=\"Description of layout (e.g., centered, rule of thirds), camera angle (e.g., eye-level, overhead), and framing (e.g., close-up, medium shot).\")\n",
        "    background_environment: str = Field(..., description=\"Details of the setting, including prominent foreground elements, background elements, surfaces, other objects, and depth of field.\")\n",
        "    lighting_color: str = Field(..., description=\"Description of light source, style (e.g., natural, studio), direction, shadows, highlights, dominant colors, and temperature.\")\n",
        "    texture_materials: str = Field(..., description=\"Specific textures visible (e.g., glossy sauce, crispy batter, smooth ceramic, condensation).\")\n",
        "    text_branding: str = Field(..., description=\"Description of the style, placement, and purpose of visible text and branding elements (e.g., font style, color, prominence, logo description). Avoids exact transcription unless critical for brand name.\")\n",
        "    mood_atmosphere: str = Field(..., description=\"Overall feeling conveyed by the image (e.g., cozy, vibrant, elegant, casual).\")\n",
        "    overall_style: str = Field(..., description=\"Characterization of the overall image style (e.g., photorealistic, illustration) including technical details like estimated camera effects (DoF, lens type), lighting style (cinematic, studio), rendering techniques, or post-processing.\")\n",
        "    # Store raw response for usage data access using PrivateAttr for internal use\n",
        "    # This avoids the Pydantic field naming conflict.\n",
        "    _raw_response: Optional[Any] = PrivateAttr(default=None)\n",
        "\n",
        "    # Optional: Add a validator to ensure fields are not empty\n",
        "    @field_validator('*', mode='before')\n",
        "    def check_not_empty(cls, value):\n",
        "        # This validator applies to the main fields, not the private attribute\n",
        "        if isinstance(value, str) and not value.strip():\n",
        "            return \"(Not specified)\" # Provide a default if empty\n",
        "        return value\n",
        "\n",
        "print(\"✅ Pydantic model 'FnbImageDescription' defined with updated field descriptions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY3MgaWojVhb",
        "outputId": "08e25383-291c-4b01-d8c3-c02076fe3a60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pydantic model 'FnbImageDescription' defined with updated field descriptions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Image Handling Function\n",
        "\n",
        "def encode_image_to_base64(image_path: str, max_size=(1024, 1024)) -> Optional[str]:\n",
        "    \"\"\"Loads an image, resizes if needed, and encodes it to base64.\"\"\"\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            # Convert image to RGB if it's not (e.g., RGBA, P)\n",
        "            if img.mode != 'RGB':\n",
        "                img = img.convert('RGB')\n",
        "\n",
        "            # Optional: Resize image to prevent exceeding token limits\n",
        "            # Uncomment the line below if images are very large\n",
        "            # print(f\"    Original size: {img.size}\")\n",
        "            # img.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
        "            # print(f\"    Resized to: {img.size}\")\n",
        "\n",
        "            buffered = BytesIO()\n",
        "            img.save(buffered, format=\"JPEG\", quality=85) # Save as JPEG with quality setting\n",
        "            img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "            # print(f\"    Encoded Base64 length: {len(img_str)}\") # For debugging size\n",
        "            return img_str\n",
        "    except FileNotFoundError:\n",
        "        print(f\"❌ Error: Image file not found at {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error encoding image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"✅ Image encoding function 'encode_image_to_base64' defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va_0svLBjdNJ",
        "outputId": "b6d63925-c852-4c6e-e656-6c50471092a3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Image encoding function 'encode_image_to_base64' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Prompt Construction Function\n",
        "\n",
        "# Baseline Prompt (as defined previously)\n",
        "BASELINE_PROMPT = \"\"\"\n",
        "Analyze the provided F&B image in meticulous detail. Generate a comprehensive description suitable for recreating this exact image using a text-to-image AI. Describe the following elements:\n",
        "\n",
        "1.  **Primary Subject(s):** Identify and describe the main food, drink, person, or element. Include details like ingredients, preparation style (e.g., grilled, fried, steamed), presentation, specific actions (e.g., pouring, eating).\n",
        "2.  **Composition & Framing:** Describe the layout (e.g., centered, rule of thirds, asymmetrical), camera angle (e.g., eye-level, overhead shot, low angle, Dutch tilt), and framing (e.g., extreme close-up, close-up, medium shot, full shot, wide shot).\n",
        "3.  **Foreground, Background & Environment:** Detail the setting, specifically describing prominent **foreground elements**, background elements, surfaces (foreground and background), other objects present, and depth of field (e.g., sharp foreground with blurred background, deep focus).\n",
        "4.  **Lighting & Color:** Describe the light source and style (e.g., bright natural daylight from window, warm indoor ambient light, dramatic studio flash, soft diffused light), direction of light, presence and softness of shadows, highlights, dominant color palette, and overall color temperature (e.g., warm tones, cool tones, vibrant, muted).\n",
        "5.  **Texture & Materials:** Mention specific textures visible (e.g., glossy sauce, crispy batter, fluffy bread, smooth ceramic plate, rough wooden board, condensation on glass, metallic sheen of cutlery).\n",
        "6.  **Text & Branding:** Describe the style, placement, and apparent purpose of any visible text (e.g., title, logo, caption, menu item). Note font style, color, and prominence. Avoid exact transcription unless essential for branding (like a main brand name). Describe logos or key branding elements.\n",
        "7.  **Mood & Atmosphere:** Describe the overall feeling conveyed by the image (e.g., cozy and intimate, bright and energetic, rustic and homely, elegant and sophisticated, casual and fun, busy and dynamic).\n",
        "8.  **Overall Style:** Characterize the overall image style (e.g., photorealistic, illustration, graphic design). Include technical details where possible, such as estimated camera/lens effects (e.g., shallow depth of field, wide-angle look), specific lighting style (e.g., cinematic, studio, natural low light), rendering techniques (e.g., cel-shaded, painterly), or post-processing hints (e.g., color grading, filters).\n",
        "\"\"\"\n",
        "\n",
        "# Category-Specific Emphasis (as defined previously)\n",
        "CATEGORY_EMPHASIS = {\n",
        "    \"Product Shot\": \"Emphasis for Product Shot: Pay extra attention to the details of the food/drink item itself – texture, color accuracy, freshness indicators (e.g., steam, droplets), plating details, garnishes, and how the lighting highlights the product's appeal. Describe the dishware/glassware precisely.\",\n",
        "    \"Lifestyle Shot\": \"Emphasis for Lifestyle Shot: Focus on the people involved – their expressions, actions, interactions with the product or each other, clothing style, and body language. Describe how the product is integrated into the scene and the overall narrative suggested (e.g., friends enjoying brunch, family dinner, solo coffee break).\",\n",
        "    \"Menu Displays\": \"Emphasis for Menu Display: Prioritize accurate transcription of all visible text, including item names, descriptions, and prices. Describe the menu's layout, typography (font style, size, weight), color scheme, any graphical elements (lines, boxes, icons), and the material/context if it's a physical menu photo (e.g., chalkboard, printed paper, digital screen). Note the overall readability and design style.\",\n",
        "    \"Promotional Graphics\": \"Emphasis for Promotional Graphic: Accurately transcribe all promotional text (offer details, dates, calls to action). Describe the graphic design elements used (e.g., background color/gradient, shapes, icons, font styles). If it combines photos and graphics, describe how they are integrated. Detail the overall visual hierarchy and intended message.\",\n",
        "    \"Branding Elements\": \"Emphasis for Branding Element: Focus intensely on the specific branding element shown (e.g., logo, packaging detail, unique sign). Describe its colors, shapes, typography, and material precisely. Explain its context within the image and how it contributes to the overall brand identity.\",\n",
        "    \"Location/Ambience Shots\": \"Emphasis for Location/Ambience: Describe the key features of the space – decor style (e.g., modern, rustic, industrial), furniture, lighting fixtures, color scheme, materials (wood, brick, metal), sense of space (cozy, spacious), cleanliness, and overall atmosphere it creates for a customer. Mention specific details like wall art, plants, table settings if visible.\",\n",
        "    \"Event Promotions\": \"Emphasis for Event Promotion: Accurately transcribe all event details (name, date, time, location, description, contact info, price). Describe any specific imagery related to the event theme (e.g., musical instruments, wine bottles, specific food). Detail the overall design style of the flyer/poster/graphic and its call to action.\",\n",
        "    \"Behind-the-Scenes (BTS)\": \"Emphasis for BTS: Describe the action taking place (e.g., cooking, plating, ingredient prep, staff interaction). Detail the environment (e.g., kitchen equipment, staff uniforms, raw ingredients) and the sense of activity or focus. Capture the candid, authentic feel typical of BTS shots.\",\n",
        "    \"Default\": \"\" # For categories not listed or if no emphasis is needed\n",
        "}\n",
        "\n",
        "def construct_prompt(category: Optional[str] = None, use_category_emphasis: bool = False) -> str:\n",
        "    \"\"\"Constructs the prompt, optionally adding category-specific emphasis.\"\"\"\n",
        "    prompt = BASELINE_PROMPT\n",
        "    if use_category_emphasis and category:\n",
        "        emphasis = CATEGORY_EMPHASIS.get(category, CATEGORY_EMPHASIS[\"Default\"])\n",
        "        if emphasis:\n",
        "            prompt += \"\\n\\n\" + emphasis\n",
        "    return prompt\n",
        "\n",
        "print(\"✅ Prompt construction function 'construct_prompt' defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRx2p7dHjhJh",
        "outputId": "7d0cda13-701e-49b6-bf7f-5b25ab58bc5f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prompt construction function 'construct_prompt' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Core Inference Function (with Token Usage)\n",
        "\n",
        "def get_structured_description_with_usage(\n",
        "    model_name: str,\n",
        "    image_base64: str,\n",
        "    prompt: str\n",
        ") -> Tuple[Optional[FnbImageDescription], Optional[Dict[str, int]]]:\n",
        "    \"\"\"\n",
        "    Sends image and prompt to a model via OpenRouter, gets a structured description,\n",
        "    and extracts token usage information.\n",
        "    Returns a tuple: (description_object, usage_dict)\n",
        "    \"\"\"\n",
        "    usage_info = None\n",
        "    description_obj = None\n",
        "    try:\n",
        "        print(f\"   Querying {model_name}...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Make the API call requesting the Pydantic model response\n",
        "        description_obj = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            response_model=FnbImageDescription,\n",
        "            max_retries=1, # Retry once on failure\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": prompt},\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{image_base64}\",\n",
        "                                # OpenAI API suggests 'detail' param, but OpenRouter might not use it\n",
        "                                # explicitly. High detail is usually default for base64.\n",
        "                                # \"detail\": \"high\"\n",
        "                            },\n",
        "                        },\n",
        "                    ],\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=2048, # Adjust as needed\n",
        "            temperature=0.2, # Lower temperature for more deterministic descriptions\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        print(f\"   ✅ Success for {model_name} in {end_time - start_time:.2f} seconds.\")\n",
        "\n",
        "        # --- Extract Token Usage ---\n",
        "        # Access the private attribute _raw_response correctly\n",
        "        raw_response = getattr(description_obj, '_raw_response', None)\n",
        "        if raw_response and hasattr(raw_response, 'usage'):\n",
        "             raw_usage = raw_response.usage\n",
        "             if raw_usage:\n",
        "                 usage_info = {\n",
        "                     \"prompt_tokens\": raw_usage.prompt_tokens,\n",
        "                     \"completion_tokens\": raw_usage.completion_tokens,\n",
        "                     \"total_tokens\": raw_usage.total_tokens,\n",
        "                 }\n",
        "                 # print(f\"      Usage: {usage_info}\") # Uncomment for debugging\n",
        "        else:\n",
        "             # Fallback if usage is not directly on the response object's attribute\n",
        "             # This might happen depending on instructor/openai library versions\n",
        "             # Try accessing from the raw response dict if possible\n",
        "             try:\n",
        "                 if description_obj and hasattr(description_obj.model_extra, 'usage'):\n",
        "                     raw_usage = description_obj.model_extra['usage']\n",
        "                     usage_info = {\n",
        "                         \"prompt_tokens\": raw_usage.prompt_tokens,\n",
        "                         \"completion_tokens\": raw_usage.completion_tokens,\n",
        "                         \"total_tokens\": raw_usage.total_tokens,\n",
        "                     }\n",
        "                     # print(f\"      Usage (fallback): {usage_info}\")\n",
        "                 else:\n",
        "                    print(f\"   ⚠️ Usage information not found in response for {model_name}.\")\n",
        "                    usage_info = {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0}\n",
        "             except Exception:\n",
        "                 print(f\"   ⚠️ Error accessing fallback usage info for {model_name}.\")\n",
        "                 usage_info = {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0}\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ❌ Error querying {model_name}:\")\n",
        "        # Print detailed traceback for debugging\n",
        "        # traceback.print_exc()\n",
        "        print(f\"      {e}\")\n",
        "        # Ensure description_obj is None if error occurs before assignment\n",
        "        description_obj = None\n",
        "        usage_info = {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0} # Default on error\n",
        "\n",
        "    return description_obj, usage_info\n",
        "\n",
        "print(\"✅ Core inference function 'get_structured_description_with_usage' using response body usage check.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_lzXrtfjnbZ",
        "outputId": "8afb1b1b-2324-467c-99da-72f5aa565e2b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Core inference function 'get_structured_description_with_usage' using response body usage check.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Configuration\n",
        "\n",
        "# --- Configuration ---\n",
        "# List of OpenRouter model identifiers to test (Update based on Step 1.2 and availability)\n",
        "# Ensure these models support vision input on OpenRouter\n",
        "MODELS_TO_TEST = [\n",
        "    #\"openai/gpt-4o-2024-11-20\",\n",
        "    #\"openai/gpt-4.1-mini\",\n",
        "    \"openai/o4-mini\",\n",
        "    #\"openai/o3\",\n",
        "    # Anthropic - Claude\n",
        "    #\"anthropic/claude-3.7-sonnet\",\n",
        "    # Google - Gemini\n",
        "    #\"google/gemini-2.5-pro-preview-03-25\",\n",
        "    #\"gemini-2.5-pro-exp-03-25\",\n",
        "    #\"google/gemini-2.5-flash-preview\",\n",
        "    # Meta - Llama\n",
        "    #\"meta-llama/llama-4-scout:free\",\n",
        "    #\"meta-llama/llama-4-maverick:free\",\n",
        "    #\"meta-llama/llama-3.2-90b-vision-instruct\",\n",
        "    # XAI - Grok\n",
        "    #\"x-ai/grok-3-beta\",\n",
        "    # Qwen\n",
        "    #qwen/qwen2.5-vl-32b-instruct\",\n",
        "]\n",
        "\n",
        "# --- !!! IMPORTANT: Define Model Pricing (per Million Tokens) !!! ---\n",
        "# GET THESE VALUES FROM https://openrouter.ai/models FOR ACCURACY\n",
        "# Prices are in USD per 1 Million tokens (Input and Output)\n",
        "MODEL_PRICING = {\n",
        "    # Model Identifier: {\"input_cost_per_M\": X.XX, \"output_cost_per_M\": Y.YY}\n",
        "    # OpenAI\n",
        "    #\"openai/gpt-4o-2024-11-20\": {\"input_cost_per_M\": 2.50, \"output_cost_per_M\": 10.00},\n",
        "    \"openai/gpt-4.1-mini\": {\"input_cost_per_M\": 0.40, \"output_cost_per_M\": 1.60},\n",
        "    \"openai/o4-mini\": {\"input_cost_per_M\": 1.10, \"output_cost_per_M\": 4.40},\n",
        "    #\"openai/o3\": {\"input_cost_per_M\": 10.00, \"output_cost_per_M\": 40.00},\n",
        "    # Anthropic - Claude\n",
        "    #\"anthropic/claude-3.7-sonnet\": {\"input_cost_per_M\": 3.00, \"output_cost_per_M\": 15.00},\n",
        "    # Google - Gemini\n",
        "    \"google/gemini-2.5-pro-preview-03-25\": {\"input_cost_per_M\": 1.25, \"output_cost_per_M\": 10.00},\n",
        "    \"gemini-2.5-pro-exp-03-25\": {\"input_cost_per_M\": 0.00, \"output_cost_per_M\": 0.00},\n",
        "    #\"google/gemini-2.5-flash-preview\": {\"input_cost_per_M\": 0.15, \"output_cost_per_M\": 0.6},\n",
        "    # Meta - Llama\n",
        "    #\"meta-llama/llama-4-scout:free\": {\"input_cost_per_M\": 0.0, \"output_cost_per_M\": 0.00},\n",
        "    #\"meta-llama/llama-4-maverick:free\": {\"input_cost_per_M\": 0.0, \"output_cost_per_M\": 0.00},\n",
        "    #\"meta-llama/llama-3.2-90b-vision-instruct\": {\"input_cost_per_M\": 0.8, \"output_cost_per_M\": 1.60},\n",
        "    # XAI - Grok\n",
        "    #\"x-ai/grok-3-beta\": {\"input_cost_per_M\": 3.0, \"output_cost_per_M\": 15.00},\n",
        "    # Qwen\n",
        "    \"qwen/qwen2.5-vl-32b-instruct\": {\"input_cost_per_M\": 0.90, \"output_cost_per_M\": 0.90},\n",
        "}\n",
        "print(\"⚠️ Ensure MODEL_PRICING dictionary is updated with current OpenRouter prices!\")\n",
        "\n",
        "\n",
        "# --- Input Data ---\n",
        "# List of images to process. Each item is a tuple: (image_id, image_path, category)\n",
        "# Replace with your actual image paths and categories from Step 1.1\n",
        "# IMAGES_TO_PROCESS = [\n",
        "#     (\"prod_001\", \"path/to/your/product_shot_1.jpg\", \"Product Shot\"),\n",
        "#     (\"life_001\", \"path/to/your/lifestyle_shot_1.png\", \"Lifestyle Shot\"),\n",
        "#     (\"menu_001\", \"path/to/your/menu_display_1.jpg\", \"Menu Displays\"),\n",
        "#     (\"promo_001\", \"path/to/your/promo_graphic_1.jpeg\", \"Promotional Graphics\"),\n",
        "#     # Add all other images from your dataset here...\n",
        "# ]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Ensure MODEL_PRICING dictionary is updated with current OpenRouter prices!\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcKsmJLaMoms",
        "outputId": "b081d16d-4f37-4b12-8816-d0fffba93553"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Main Processing Workflow (with Cost Estimation)\n",
        "# --- Workflow Execution ---\n",
        "\n",
        "results_list = []\n",
        "\n",
        "# Use tqdm for progress bar\n",
        "for image_id, image_path, category in tqdm(IMAGES_TO_PROCESS, desc=\"Processing Images\"):\n",
        "    if image_id not in [\"menu_0003\"]:\n",
        "      continue\n",
        "    print(f\"\\nProcessing Image: {image_id} ({category}) - {image_path}\")\n",
        "\n",
        "    # 1. Encode Image\n",
        "    image_base64 = encode_image_to_base64(image_path)\n",
        "    if not image_base64:\n",
        "        print(f\"   Skipping image {image_id} due to encoding error.\")\n",
        "        continue\n",
        "\n",
        "    # 2. Construct Prompt (Choose whether to use category emphasis)\n",
        "    # Set use_category_emphasis=True to add specific instructions\n",
        "    use_category_emphasis_flag = True # Or True\n",
        "    prompt_text = construct_prompt(category, use_category_emphasis=use_category_emphasis_flag)\n",
        "\n",
        "    # 3. Iterate through models\n",
        "    for model_name in tqdm(MODELS_TO_TEST, desc=f\"  Models for {image_id}\", leave=False):\n",
        "        description_obj, usage_info = get_structured_description_with_usage(model_name, image_base64, prompt_text)\n",
        "\n",
        "        # --- Calculate Estimated Cost ---\n",
        "        estimated_cost = 0.0\n",
        "        prompt_tokens = 0\n",
        "        completion_tokens = 0\n",
        "        total_tokens = 0\n",
        "\n",
        "        if usage_info:\n",
        "            prompt_tokens = usage_info.get(\"prompt_tokens\", 0)\n",
        "            completion_tokens = usage_info.get(\"completion_tokens\", 0)\n",
        "            total_tokens = usage_info.get(\"total_tokens\", 0)\n",
        "\n",
        "            if model_name in MODEL_PRICING:\n",
        "                pricing = MODEL_PRICING[model_name]\n",
        "                input_cost = (prompt_tokens / 1_000_000) * pricing[\"input_cost_per_M\"]\n",
        "                output_cost = (completion_tokens / 1_000_000) * pricing[\"output_cost_per_M\"]\n",
        "                estimated_cost = input_cost + output_cost\n",
        "            else:\n",
        "                print(f\"   ⚠️ Pricing not found for model {model_name}. Cost estimation skipped.\")\n",
        "\n",
        "        # Store results\n",
        "        result_data = {\n",
        "            \"Image ID\": image_id,\n",
        "            \"Image Path\": image_path,\n",
        "            \"Category\": category,\n",
        "            \"Model\": model_name,\n",
        "            \"Prompt Type\": \"Category-Specific\" if use_category_emphasis_flag and category else \"Baseline\",\n",
        "            \"Prompt Tokens\": prompt_tokens,\n",
        "            \"Completion Tokens\": completion_tokens,\n",
        "            \"Total Tokens\": total_tokens,\n",
        "            \"Estimated Cost (USD)\": round(estimated_cost, 6) # Round to 6 decimal places\n",
        "        }\n",
        "\n",
        "        if description_obj:\n",
        "            # Add structured fields to the result dictionary\n",
        "            # Use model_dump() which correctly handles Pydantic models without private attributes\n",
        "            result_data.update(description_obj.model_dump())\n",
        "            result_data[\"Status\"] = \"Success\"\n",
        "        else:\n",
        "            # Add empty fields if the description failed\n",
        "            # Iterate through the model's defined fields\n",
        "            for field_name in FnbImageDescription.model_fields:\n",
        "                 result_data[field_name] = \"ERROR\"\n",
        "            result_data[\"Status\"] = \"Error\"\n",
        "\n",
        "        results_list.append(result_data)\n",
        "\n",
        "print(\"\\n✅ Workflow finished.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8e6d8264b6b64a8a8ef92d2431cbab33",
            "86c9ba8318964c9e9a373501a79ad6be",
            "37d1231d6e5e41c59c99016635145141",
            "3dafe5112ad8475d916ba9c0ea4b517b",
            "a055cbc607cd4cd2af99b14a84bd1af0",
            "587f948dab6f43e092ab64590db25af7",
            "17f56e0f322f45939bf61aedfc3a00d1",
            "bd231bc478e24e2bade2d3ed12baed5b",
            "5072f60c47ba484ba16923bfcb29c257",
            "69badbab25aa4150ba332764445d327c",
            "a28daaf08cd44423946ff0ff231627a4",
            "453dc98d824c416d8f8921c08205e51c",
            "d068f318dd1b4f84b9908d2dd710672b",
            "62e1628ef24a46feaed6a34247ed017f",
            "3a6f40dd496a4ca495c98bcac8865f4c",
            "0d3b73d7538443b0afb9c7d40adbe955",
            "c5d0a2eb5d3b474da809dd26a2ff85a2",
            "b5cd74cc34b440dfbf0e9fb03cd1f737",
            "5a1d223cd7224517ad2257ac30d56715",
            "7b34432a82e04e6ba8674a67adbd0980",
            "85ebdc4fa9fe4d3b8051045d1b45e6bb",
            "a41c4b879e96406398fec6dc0b594cf8"
          ]
        },
        "id": "AOycJQSQj7Hp",
        "outputId": "2849970e-d830-4b02-f9f8-ea58f3a6178c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Images:   0%|          | 0/24 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e6d8264b6b64a8a8ef92d2431cbab33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Image: menu_0003 (Menu Displays) - /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu_0003.JPG\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Models for menu_0003:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "453dc98d824c416d8f8921c08205e51c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Querying qwen/qwen2.5-vl-32b-instruct...\n",
            "   ✅ Success for qwen/qwen2.5-vl-32b-instruct in 16.38 seconds.\n",
            "\n",
            "✅ Workflow finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display Results in a DataFrame\n",
        "\n",
        "# Convert results to DataFrame early for easier processing\n",
        "results_df = pd.DataFrame() # Initialize empty DataFrame\n",
        "if results_list:\n",
        "    results_df = pd.DataFrame(results_list)\n",
        "\n",
        "    # Define column order for better readability\n",
        "    display_column_order = [\n",
        "        \"Image ID\", \"Category\", \"Model\", \"Status\", \"Prompt Type\",\n",
        "        \"Prompt Tokens\", \"Completion Tokens\", \"Total Tokens\", \"Estimated Cost (USD)\",\n",
        "        # Add the description fields\n",
        "        \"primary_subject\", \"composition_framing\", \"background_environment\",\n",
        "        \"lighting_color\", \"texture_materials\", \"text_branding\",\n",
        "        \"mood_atmosphere\", \"overall_style\",\n",
        "        \"Image Path\" # Include image path for reference\n",
        "    ]\n",
        "    # Ensure all expected columns exist before reordering\n",
        "    results_df = results_df.reindex(columns=display_column_order, fill_value=None)\n",
        "\n",
        "\n",
        "    # Set display options for better readability\n",
        "    pd.set_option('display.max_rows', 50) # Adjust as needed\n",
        "    pd.set_option('display.max_columns', None)\n",
        "    pd.set_option('display.width', 1000) # Adjust for wider terminal/output\n",
        "    pd.set_option('display.max_colwidth', 100) # Adjust width as needed\n",
        "\n",
        "    print(\"\\n--- Comparison Results (DataFrame) ---\")\n",
        "    # Display the DataFrame\n",
        "    display(results_df)\n",
        "\n",
        "    # --- Optional: Calculate and Display Summary Statistics ---\n",
        "    print(\"\\n--- Summary Statistics ---\")\n",
        "    # Total cost\n",
        "    total_estimated_cost = results_df[\"Estimated Cost (USD)\"].sum()\n",
        "    print(f\"Total Estimated Cost: ${total_estimated_cost:.6f}\")\n",
        "\n",
        "    # Average cost per model\n",
        "    avg_cost_per_model = results_df.groupby(\"Model\")[\"Estimated Cost (USD)\"].mean()\n",
        "    print(\"\\nAverage Estimated Cost per Model:\")\n",
        "    display(avg_cost_per_model)\n",
        "\n",
        "    # Average tokens per model\n",
        "    avg_tokens_per_model = results_df.groupby(\"Model\")[[\"Prompt Tokens\", \"Completion Tokens\", \"Total Tokens\"]].mean()\n",
        "    print(\"\\nAverage Tokens per Model:\")\n",
        "    display(avg_tokens_per_model)\n",
        "\n",
        "\n",
        "    # --- Optional: Save results to CSV ---\n",
        "    # try:\n",
        "    #     results_df.to_csv(\"fnb_llm_evaluation_results_with_cost.csv\", index=False)\n",
        "    #     print(\"\\n✅ Results saved to fnb_llm_evaluation_results_with_cost.csv\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"\\n❌ Error saving results to CSV: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo results generated.\")\n"
      ],
      "metadata": {
        "id": "vmDeFRlHWqrs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "outputId": "91331895-ff84-489b-ced9-675ca5d60fad"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Comparison Results (DataFrame) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    Image ID       Category                         Model   Status        Prompt Type  Prompt Tokens  Completion Tokens  Total Tokens  Estimated Cost (USD)                                                                                      primary_subject                                                                                  composition_framing                                                                               background_environment                                                                                       lighting_color                                                                                    texture_materials                                                                                        text_branding                                                                                      mood_atmosphere                                                                                        overall_style  \\\n",
              "0  menu_0003  Menu Displays  qwen/qwen2.5-vl-32b-instruct  Success  Category-Specific           3525                813          4338              0.003904  The primary subjects are two sandwiches displayed prominently. The top sandwich is a hearty, mul...  The composition follows a symmetrical layout with the two sandwiches placed centrally, one above...  The background is a textured, beige-brown paper-like surface, giving the image a rustic and casu...  The lighting is warm and soft, likely simulating natural daylight. The light source appears to b...  The textures are varied and detailed. The top sandwich has a crispy, golden-brown bun with a sli...  The text is prominently displayed in bold, playful fonts. The main heading \"灵感简餐\" (Inspiration S...  The overall mood is cozy and inviting, with a casual and homely feel. The warm lighting, rustic ...  The overall style is photorealistic with a touch of graphic design elements. The image combines ...   \n",
              "\n",
              "                                                                                            Image Path  \n",
              "0  /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4716264-3f04-48f3-87ad-cfda924b42b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image ID</th>\n",
              "      <th>Category</th>\n",
              "      <th>Model</th>\n",
              "      <th>Status</th>\n",
              "      <th>Prompt Type</th>\n",
              "      <th>Prompt Tokens</th>\n",
              "      <th>Completion Tokens</th>\n",
              "      <th>Total Tokens</th>\n",
              "      <th>Estimated Cost (USD)</th>\n",
              "      <th>primary_subject</th>\n",
              "      <th>composition_framing</th>\n",
              "      <th>background_environment</th>\n",
              "      <th>lighting_color</th>\n",
              "      <th>texture_materials</th>\n",
              "      <th>text_branding</th>\n",
              "      <th>mood_atmosphere</th>\n",
              "      <th>overall_style</th>\n",
              "      <th>Image Path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>menu_0003</td>\n",
              "      <td>Menu Displays</td>\n",
              "      <td>qwen/qwen2.5-vl-32b-instruct</td>\n",
              "      <td>Success</td>\n",
              "      <td>Category-Specific</td>\n",
              "      <td>3525</td>\n",
              "      <td>813</td>\n",
              "      <td>4338</td>\n",
              "      <td>0.003904</td>\n",
              "      <td>The primary subjects are two sandwiches displayed prominently. The top sandwich is a hearty, mul...</td>\n",
              "      <td>The composition follows a symmetrical layout with the two sandwiches placed centrally, one above...</td>\n",
              "      <td>The background is a textured, beige-brown paper-like surface, giving the image a rustic and casu...</td>\n",
              "      <td>The lighting is warm and soft, likely simulating natural daylight. The light source appears to b...</td>\n",
              "      <td>The textures are varied and detailed. The top sandwich has a crispy, golden-brown bun with a sli...</td>\n",
              "      <td>The text is prominently displayed in bold, playful fonts. The main heading \"灵感简餐\" (Inspiration S...</td>\n",
              "      <td>The overall mood is cozy and inviting, with a casual and homely feel. The warm lighting, rustic ...</td>\n",
              "      <td>The overall style is photorealistic with a touch of graphic design elements. The image combines ...</td>\n",
              "      <td>/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4716264-3f04-48f3-87ad-cfda924b42b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e4716264-3f04-48f3-87ad-cfda924b42b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e4716264-3f04-48f3-87ad-cfda924b42b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4bc69016-bfd3-48d6-b923-9c3406db48fc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4bc69016-bfd3-48d6-b923-9c3406db48fc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Image ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"menu_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Menu Displays\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"qwen/qwen2.5-vl-32b-instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Status\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Success\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt Type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Category-Specific\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3525,\n        \"max\": 3525,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3525\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Completion Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 813,\n        \"max\": 813,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          813\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4338,\n        \"max\": 4338,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Estimated Cost (USD)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.003904,\n        \"max\": 0.003904,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.003904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"primary_subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The primary subjects are two sandwiches displayed prominently. The top sandwich is a hearty, multi-layered sandwich with visible ingredients including slices of roasted meat (likely beef), melted cheese, mushrooms, onions, and a glossy sauce. The bottom sandwich is a croissant-style sandwich filled with scrambled eggs, a slice of ham, and a creamy sauce, giving it a soft and fluffy appearance. The sandwiches are presented on a rustic, crumpled paper background, emphasizing their casual and appetizing nature.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"composition_framing\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The composition follows a symmetrical layout with the two sandwiches placed centrally, one above the other. The camera angle is slightly elevated, providing a clear view of the sandwiches' layers and ingredients. The framing is a medium shot, capturing the sandwiches in full while also including descriptive text and branding elements around them. The overall layout is balanced, with text and graphics strategically placed to guide the viewer's attention.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"background_environment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The background is a textured, beige-brown paper-like surface, giving the image a rustic and casual feel. The sandwiches are placed on crumpled paper, adding to the informal and inviting atmosphere. The background is relatively simple, with no distracting elements, ensuring the sandwiches remain the focal point. The depth of field is shallow, keeping the sandwiches sharp while slightly blurring the edges of the paper and background.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lighting_color\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The lighting is warm and soft, likely simulating natural daylight. The light source appears to be coming from above, creating gentle highlights on the sandwiches' surfaces and ingredients. Shadows are soft and subtle, enhancing the textures without overpowering the image. The overall color palette is warm, with earthy tones and a slight golden hue, contributing to the cozy and appetizing mood.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texture_materials\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The textures are varied and detailed. The top sandwich has a crispy, golden-brown bun with a slightly puffy texture. The meat slices appear tender and slightly glossy, while the mushrooms and onions have a soft, slightly translucent texture. The bottom sandwich features a flaky, golden croissant with a soft, pillowy interior. The scrambled eggs are fluffy and slightly runny, and the creamy sauce has a smooth, glossy texture. The crumpled paper adds a rough, tactile texture to the foreground.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_branding\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The text is prominently displayed in bold, playful fonts. The main heading \\\"\\u7075\\u611f\\u7b80\\u9910\\\" (Inspiration Simple Meal) is in large, orange, distressed-style text, giving it a casual and inviting feel. Smaller text describes the sandwiches, listing ingredients such as \\\"\\u829d\\u829d\\u718f\\u725b\\u4e09\\u660e\\u6cbb\\\" (Cheese Roasted Beef Sandwich) and \\\"\\u732b\\u5c71\\u738b\\u69b4\\u83b2\\u5ae9\\u9e21\\u725b\\u89d2\\\" (Mao Shan Wang Durian Soft Chicken Croissant). The promotional offer \\\"\\u4e70\\u4e00\\u9001\\u4e00\\\" (Buy One, Get One Free) is in a bold, blue box at the top. The price \\\"\\u00a525/\\u4e2a\\\" (25 Yuan each) is displayed in a red circle, making it stand out. The text is strategically placed to complement the sandwiches without overwhelming the image.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mood_atmosphere\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The overall mood is cozy and inviting, with a casual and homely feel. The warm lighting, rustic background, and detailed textures of the sandwiches create a sense of comfort and satisfaction. The playful text and promotional offer add a touch of excitement and value, making the image feel approachable and appealing.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_style\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The overall style is photorealistic with a touch of graphic design elements. The image combines high-quality photography of the sandwiches with stylized text and a rustic background. The use of warm lighting and shallow depth of field adds a cinematic quality, while the distressed text and crumpled paper give it a handcrafted, artisanal feel. The image appears to be professionally edited, with careful attention to color grading and composition to enhance the visual appeal.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Image Path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu_0003.JPG\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Summary Statistics ---\n",
            "Total Estimated Cost: $0.003904\n",
            "\n",
            "Average Estimated Cost per Model:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Model\n",
              "qwen/qwen2.5-vl-32b-instruct    0.003904\n",
              "Name: Estimated Cost (USD), dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Estimated Cost (USD)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>qwen/qwen2.5-vl-32b-instruct</th>\n",
              "      <td>0.003904</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Tokens per Model:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              Prompt Tokens  Completion Tokens  Total Tokens\n",
              "Model                                                                       \n",
              "qwen/qwen2.5-vl-32b-instruct         3525.0              813.0        4338.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-586751ed-acd2-49ad-b094-2de0f5bb42d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prompt Tokens</th>\n",
              "      <th>Completion Tokens</th>\n",
              "      <th>Total Tokens</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>qwen/qwen2.5-vl-32b-instruct</th>\n",
              "      <td>3525.0</td>\n",
              "      <td>813.0</td>\n",
              "      <td>4338.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-586751ed-acd2-49ad-b094-2de0f5bb42d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-586751ed-acd2-49ad-b094-2de0f5bb42d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-586751ed-acd2-49ad-b094-2de0f5bb42d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ea88a09f-0e2a-4d58-8c7d-a44d026b8cd9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('avg_tokens_per_model')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ea88a09f-0e2a-4d58-8c7d-a44d026b8cd9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('avg_tokens_per_model');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "avg_tokens_per_model",
              "summary": "{\n  \"name\": \"avg_tokens_per_model\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"qwen/qwen2.5-vl-32b-instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Prompt Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3525.0,\n        \"max\": 3525.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3525.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Completion Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 813.0,\n        \"max\": 813.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          813.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total Tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 4338.0,\n        \"max\": 4338.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4338.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Export Result to JSONL/CSV\n",
        "\n",
        "# Example filtering (adjust as needed)\n",
        "selected_model = \"openai/o4-mini\" # Or your best model\n",
        "\n",
        "# Assuming you've added manual scores back to the df or have another way to filter\n",
        "# For simplicity, let's just select successful runs from one model for now:\n",
        "selected_descriptions_df = results_df[\n",
        "    (results_df['Model'] == selected_model) &\n",
        "    (results_df['Status'] == 'Success')\n",
        "].copy() # Filter for the best model's successful runs\n",
        "\n",
        "# Select relevant columns (don't need tokens/cost here)\n",
        "columns_to_export = [\n",
        "    \"Image ID\", \"Image Path\", \"Category\", \"Model\", # Keep original model info\n",
        "    \"primary_subject\", \"composition_framing\", \"background_environment\",\n",
        "    \"lighting_color\", \"texture_materials\", \"text_branding\",\n",
        "    \"mood_atmosphere\", \"overall_style\"\n",
        "]\n",
        "export_df = selected_descriptions_df[columns_to_export]\n",
        "\n",
        "# Export to CSV\n",
        "# --- Prepare for Excel Export ---\n",
        "now = datetime.datetime.now()\n",
        "# Use underscores in timestamp for filename safety\n",
        "formatted_date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "export_filename = f\"image_descriptions_{formatted_date_time}.csv\"\n",
        "export_df.to_csv(export_filename, index=False)\n",
        "print(f\"✅ Selected descriptions exported to {export_filename}\")\n",
        "\n",
        "# OR Export to JSON Lines (good for structured text)\n",
        "export_filename_jsonl = f\"image_descriptions_{formatted_date_time}.jsonl\"\n",
        "export_df.to_json(\n",
        "    export_filename_jsonl,\n",
        "    orient='records',      # Structure for JSON Lines\n",
        "    lines=True,            # Ensure one JSON object per line\n",
        "    force_ascii=False,     # *** THIS IS THE KEY CHANGE *** Allows UTF-8 characters\n",
        ")\n",
        "\n",
        "print(f\"✅ Selected descriptions exported to {export_filename_jsonl}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keQbhbKj8tve",
        "outputId": "284234e6-4dac-42dc-eb0f-669fb471a294"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Selected descriptions exported to image_descriptions_2025-04-23_21-35-07.csv\n",
            "✅ Selected descriptions exported to image_descriptions_2025-04-23_21-35-07.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Export Result to XSLX (Formatted) + Image Gen Prompt\n",
        "\n",
        "# Example filtering (adjust as needed)\n",
        "selected_model = \"openai/o4-mini\" # Or your best model\n",
        "\n",
        "selected_descriptions_df = results_df[\n",
        "    (results_df['Model'] == selected_model) &\n",
        "    (results_df['Status'] == 'Success')\n",
        "].copy() # Filter for the best model's successful runs\n",
        "\n",
        "# Select relevant columns (don't need tokens/cost here)\n",
        "columns_to_export = [\n",
        "    \"Image ID\", \"Image Path\", \"Category\", \"Model\", # Keep original model info\n",
        "    \"primary_subject\", \"composition_framing\", \"background_environment\",\n",
        "    \"lighting_color\", \"texture_materials\", \"text_branding\",\n",
        "    \"mood_atmosphere\", \"overall_style\"\n",
        "]\n",
        "# Ensure only existing columns are selected\n",
        "columns_to_export = [col for col in columns_to_export if col in selected_descriptions_df.columns]\n",
        "export_df = selected_descriptions_df[columns_to_export]\n",
        "\n",
        "def create_image_prompt(row):\n",
        "    \"\"\"Creates a formatted string prompt from row data.\"\"\"\n",
        "    prompt_parts = []\n",
        "    # Define column names and their desired labels in the prompt string\n",
        "    # Adjust this dictionary based on exactly which fields you want\n",
        "    fields_to_include = {\n",
        "        \"Category\": \"Category\",\n",
        "        \"primary_subject\": \"Primary subject\",\n",
        "        \"composition_framing\": \"Composition framing\",\n",
        "        \"background_environment\": \"Background environment\",\n",
        "        \"lighting_color\": \"Lighting color\",\n",
        "        \"texture_materials\": \"Texture materials\",\n",
        "        \"text_branding\": \"Text branding\",\n",
        "        \"mood_atmosphere\": \"Mood atmosphere\",\n",
        "        \"overall_style\": \"Overall style\"\n",
        "    }\n",
        "\n",
        "    for col_name, label in fields_to_include.items():\n",
        "        value = row.get(col_name) # Use .get() in case a column is missing\n",
        "        # Check if value is not null/NaN AND not an empty string after stripping whitespace\n",
        "        if pd.notna(value) and str(value).strip():\n",
        "            prompt_parts.append(f\"{label}: {str(value).strip()}\") # Add label and value\n",
        "\n",
        "    return \", \".join(prompt_parts) # Join valid parts with \", \"\n",
        "\n",
        "# Apply the function row-wise AFTER filtering but BEFORE splitting/formatting for Excel\n",
        "# Ensure export_df exists and potentially has rows before applying\n",
        "if not export_df.empty:\n",
        "     export_df['image_prompt'] = export_df.apply(create_image_prompt, axis=1)\n",
        "else:\n",
        "     # If df is empty, add an empty column so subsequent code doesn't fail if it expects it\n",
        "     export_df['image_prompt'] = pd.Series(dtype='object')\n",
        "\n",
        "# --- Configuration for Excel Output ---\n",
        "\n",
        "# Define columns to actually display in the table on each sheet (EXCLUDING Category & Model)\n",
        "columns_to_display_in_table = [\n",
        "    \"Image ID\", \"Image Path\", \"primary_subject\", \"composition_framing\",\n",
        "    \"background_environment\", \"lighting_color\", \"texture_materials\",\n",
        "    \"text_branding\", \"mood_atmosphere\", \"overall_style\", \"image_prompt\"\n",
        "]\n",
        "# Ensure these columns actually exist in the dataframe\n",
        "columns_to_display_in_table = [col for col in columns_to_display_in_table if col in export_df.columns]\n",
        "\n",
        "\n",
        "# Define suggested widths ONLY for the columns being displayed in the table\n",
        "# Adjust widths as needed to help fit content on one page with wrapping\n",
        "col_widths = {\n",
        "    'Image ID': 8,\n",
        "    'Image Path': 10,\n",
        "    'primary_subject': 25,\n",
        "    'composition_framing': 25,\n",
        "    'background_environment': 25,\n",
        "    'lighting_color': 25,\n",
        "    'texture_materials': 25,\n",
        "    'text_branding': 25,\n",
        "    'mood_atmosphere': 25,\n",
        "    'overall_style': 25,\n",
        "    'image_prompt': 25,\n",
        "}\n",
        "# Filter widths dictionary to only include columns we are actually displaying\n",
        "col_widths = {k: v for k, v in col_widths.items() if k in columns_to_display_in_table}\n",
        "\n",
        "# Define which of the DISPLAYED columns should have text wrapping enabled\n",
        "columns_to_wrap = [col for col in columns_to_display_in_table if col not in ['Image ID']]\n",
        "\n",
        "\n",
        "# --- Prepare for Excel Export ---\n",
        "now = datetime.datetime.now()\n",
        "# Use underscores in timestamp for filename safety\n",
        "formatted_date_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "# CHANGE FILENAME to reflect Excel output and structure\n",
        "# Replace invalid filename characters from model name\n",
        "safe_model_name = re.sub(r'[\\\\/*?:\"<>|]', '_', selected_model)\n",
        "export_filename_excel = f\"image_descriptions_by_category_{formatted_date_time}.xlsx\"\n",
        "\n",
        "# Function to sanitize sheet names (Excel limits length and characters)\n",
        "def sanitize_sheet_name(name):\n",
        "    name = str(name) # Ensure it's a string\n",
        "    name = re.sub(r'[\\\\/*?:\\[\\]]', '_', name) # Remove invalid characters\n",
        "    return name[:31] # Truncate to Excel's limit\n",
        "\n",
        "# Get unique categories and the model name from the filtered dataframe\n",
        "if not export_df.empty:\n",
        "    unique_categories = sorted(export_df['Category'].unique())\n",
        "    # Model name should be consistent due to the initial filter\n",
        "    model_name = export_df['Model'].iloc[0]\n",
        "else:\n",
        "    unique_categories = []\n",
        "    model_name = selected_model # Fallback if df is empty but filter was applied\n",
        "    print(f\"Warning: Filtered DataFrame 'export_df' for model '{selected_model}' is empty.\")\n",
        "\n",
        "\n",
        "# --- Create Excel File with Sheets per Category (Replaces CSV Export and Truncation)---\n",
        "# REMOVED: Truncation logic (path_max_length, paragraph_max_length, loop for truncation)\n",
        "# REMOVED: export_df_truncated definition\n",
        "\n",
        "with pd.ExcelWriter(export_filename_excel, engine='xlsxwriter') as writer:\n",
        "    if not unique_categories:\n",
        "        # Handle case of no data/categories after filtering\n",
        "        workbook = writer.book\n",
        "        worksheet = workbook.add_worksheet(\"No Data\")\n",
        "        worksheet.write('A1', f\"No successful runs found for model '{selected_model}'.\")\n",
        "        print(f\"INFO: No data to write for model '{selected_model}'. Excel file created with 'No Data' sheet.\")\n",
        "    else:\n",
        "        print(f\"Processing {len(unique_categories)} categories for model '{model_name}'...\")\n",
        "        for category in unique_categories:\n",
        "            sheet_name = sanitize_sheet_name(category)\n",
        "            print(f\"  Creating sheet: {sheet_name} (Category: {category})\")\n",
        "\n",
        "            # Filter data for the current category\n",
        "            df_category_subset = export_df[export_df['Category'] == category].copy()\n",
        "\n",
        "            # Select only the columns we want to display in the table for this sheet\n",
        "            df_to_write = df_category_subset[columns_to_display_in_table]\n",
        "\n",
        "            # Write the filtered data to the specific sheet, starting data below headers\n",
        "            # startrow=2 means data headers begin on Excel row 3\n",
        "            df_to_write.to_excel(writer, sheet_name=sheet_name, index=False, startrow=2, header=True)\n",
        "\n",
        "            # --- Get workbook and worksheet objects ---\n",
        "            workbook = writer.book\n",
        "            worksheet = writer.sheets[sheet_name]\n",
        "\n",
        "            # --- Write Custom Header (Category & Model) in Row 1 (index 0) ---\n",
        "            header_format = workbook.add_format({\n",
        "                'bold': True, 'font_size': 11, 'align': 'left', 'valign': 'vcenter',\n",
        "                'bg_color': '#F0F0F0', 'bottom': 1 # Light grey bg, bottom border\n",
        "            })\n",
        "            header_text = f\"Category: {category}   |   Model: {model_name}\"\n",
        "            worksheet.merge_range('A1:C1', header_text, header_format) # Merge A1:C1 for title\n",
        "            worksheet.set_row(0, 20) # Set height for the header row (row 1 in Excel)\n",
        "\n",
        "            # --- Apply Formatting (Wrapping & Widths) to Data Table Columns ---\n",
        "            # Format for cells where text should wrap\n",
        "            wrap_format = workbook.add_format({\n",
        "                'text_wrap': True,\n",
        "                'valign': 'top' # Align text to the top in wrapped cells\n",
        "            })\n",
        "            # Optional: Format for cells that don't need wrapping (e.g., Image ID)\n",
        "            # default_format = workbook.add_format({'valign': 'top'})\n",
        "\n",
        "            # Iterate through columns that are actually written to the sheet\n",
        "            for i, col_name in enumerate(df_to_write.columns):\n",
        "                width = col_widths.get(col_name, 15) # Get width, default 15 if not set\n",
        "                if col_name in columns_to_wrap:\n",
        "                    # Apply width AND the wrap format to this column\n",
        "                    worksheet.set_column(i, i, width, wrap_format)\n",
        "                else:\n",
        "                    # Apply width only (using default cell format)\n",
        "                    worksheet.set_column(i, i, width) #, default_format)\n",
        "\n",
        "            # Optional: Freeze top header row and column headers row for scrolling\n",
        "            # Freezes rows 1, 2, 3 (our header, blank row, column names)\n",
        "            worksheet.freeze_panes(3, 0)\n",
        "\n",
        "# Use the new Excel filename in the final print statement\n",
        "print(f\"\\n✅ Descriptions exported by category to {export_filename_excel}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91FZkUnfv4jw",
        "outputId": "31d75b0e-dd64-4cdb-c355-db6055d0aabf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1 categories for model 'qwen/qwen2.5-vl-32b-instruct'...\n",
            "  Creating sheet: Menu Displays (Category: Menu Displays)\n",
            "\n",
            "✅ Descriptions exported by category to image_descriptions_by_category_2025-04-23_22-25-54.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-c0ee2fc300df>:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  export_df['image_prompt'] = export_df.apply(create_image_prompt, axis=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate HTML Report for Visual Evaluation\n",
        "\n",
        "# --- Configuration for HTML Report ---\n",
        "HTML_REPORT_FILENAME = \"fnb_evaluation_report_5.html\"\n",
        "# Set this path if your images are in a specific folder relative to the notebook\n",
        "# or use absolute paths in IMAGES_TO_PROCESS. Leave as \"\" if paths in\n",
        "# IMAGES_TO_PROCESS are already correct relative to the HTML file location.\n",
        "# IMAGE_BASE_PATH_FOR_HTML = \"images/\" # Example: \"images/\" or \"/path/to/images/\"\n",
        "IMAGE_BASE_PATH_FOR_HTML = \"\" # Assume paths in df are correct relative to HTML\n",
        "\n",
        "# Define the HTML template using Jinja2 syntax in a string\n",
        "html_template_string = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>F&B Image Evaluation Report</title>\n",
        "    <style>\n",
        "        body { font-family: sans-serif; margin: 20px; line-height: 1.6; }\n",
        "        .image-section { margin-bottom: 40px; border-bottom: 2px solid #eee; padding-bottom: 20px; }\n",
        "        .image-container img { max-width: 400px; max-height: 400px; border: 1px solid #ccc; margin-bottom: 15px; }\n",
        "        table { border-collapse: collapse; width: 100%; margin-top: 15px; font-size: 0.9em; }\n",
        "        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; vertical-align: top; }\n",
        "        th { background-color: #f2f2f2; }\n",
        "        tr:nth-child(even) { background-color: #f9f9f9; }\n",
        "        td:first-child { font-weight: bold; min-width: 150px; } /* Model name column */\n",
        "        .status-success { color: green; }\n",
        "        .status-error { color: red; font-weight: bold; }\n",
        "        .description-cell { white-space: pre-wrap; word-wrap: break-word; } /* Wrap long text */\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h1>F&B Image Evaluation Report</h1>\n",
        "    <p>Date Generated: {{ generation_date }}</p>\n",
        "\n",
        "    {% for image_id, group in results.groupby('Image ID') %}\n",
        "    <div class=\"image-section\">\n",
        "        <h2>Image ID: {{ image_id }}</h2>\n",
        "        <p><strong>Category:</strong> {{ group['Category'].iloc[0] }}</p>\n",
        "        <div class=\"image-container\">\n",
        "            {% set img_path = image_base_path + group['Image Path'].iloc[0] %}\n",
        "            <img src=\"{{ img_path }}\" alt=\"Image {{ image_id }}\" onerror=\"this.alt='Image not found at {{ img_path }}'; this.style.border='1px solid red';\">\n",
        "        </div>\n",
        "\n",
        "        <table>\n",
        "            <thead>\n",
        "                <tr>\n",
        "                    <th>Model</th>\n",
        "                    <th>Status</th>\n",
        "                    <th>Total Tokens</th>\n",
        "                    <th>Est. Cost (USD)</th>\n",
        "                    <th>Primary Subject</th>\n",
        "                    <th>Composition/Framing</th>\n",
        "                    <th>Background/Environment</th>\n",
        "                    <th>Lighting/Color</th>\n",
        "                    <th>Texture/Materials</th>\n",
        "                    <th>Text/Branding</th>\n",
        "                    <th>Mood/Atmosphere</th>\n",
        "                    <th>Overall Style</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "                {% for index, row in group.iterrows() %}\n",
        "                <tr>\n",
        "                    <td>{{ row['Model'] }}</td>\n",
        "                    <td class=\"status-{{ row['Status'].lower() }}\">{{ row['Status'] }}</td>\n",
        "                    <td>{{ row['Total Tokens'] }}</td>\n",
        "                    <td>{{ \"%.6f\"|format(row['Estimated Cost (USD)']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['primary_subject']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['composition_framing']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['background_environment']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['lighting_color']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['texture_materials']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['text_branding']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['mood_atmosphere']) }}</td>\n",
        "                    <td class=\"description-cell\">{{ escape(row['overall_style']) }}</td>\n",
        "                </tr>\n",
        "                {% endfor %}\n",
        "            </tbody>\n",
        "        </table>\n",
        "    </div>\n",
        "    {% endfor %}\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "def generate_html_report(df, output_filename, image_base_path=\"\"):\n",
        "    \"\"\"Generates an HTML report from the results DataFrame.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"❌ Cannot generate report: Results DataFrame is empty.\")\n",
        "        return\n",
        "\n",
        "    # Ensure necessary columns exist, especially 'Image Path'\n",
        "    if 'Image Path' not in df.columns:\n",
        "        print(\"❌ Cannot generate report: 'Image Path' column missing in results.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Using Jinja2 directly with the template string\n",
        "        env = Environment(loader=None, autoescape=select_autoescape(['html', 'xml']))\n",
        "        env.globals['escape'] = html.escape # Add escape function to template context\n",
        "        template = env.from_string(html_template_string)\n",
        "\n",
        "        generation_date = time.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
        "\n",
        "        # Render the template\n",
        "        html_content = template.render(\n",
        "            results=df,\n",
        "            generation_date=generation_date,\n",
        "            image_base_path=image_base_path\n",
        "        )\n",
        "\n",
        "        # Write to file\n",
        "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(html_content)\n",
        "        print(f\"✅ HTML report generated successfully: {output_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error generating HTML report: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "# --- Generate the Report ---\n",
        "# Make sure results_df exists and is populated from the previous cell\n",
        "if 'results_df' in locals() and not results_df.empty:\n",
        "     generate_html_report(results_df, HTML_REPORT_FILENAME, IMAGE_BASE_PATH_FOR_HTML)\n",
        "elif not results_list:\n",
        "     print(\"⚠️ Skipping HTML report generation because no results were generated in the workflow.\")\n",
        "else:\n",
        "     print(\"⚠️ Skipping HTML report generation. Ensure the main workflow cell has been run successfully and 'results_df' exists.\")\n",
        "\n",
        "\n",
        "from IPython.display import HTML\n",
        "\n",
        "with open('fnb_evaluation_report_5.html', 'r') as f:  # Assuming your file is named 'fnb_evaluation_report.html'\n",
        "  html_content = f.read()\n",
        "\n",
        "display(HTML(html_content))\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/content/drive/MyDrive/AI%20Imagery%20Marketing%20Tool/Colab%20Notebook/dataset_image/Menu%20Displays/menu_0003.JPG": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kxLd8mdPHpdn",
        "outputId": "3cd5e8ed-fc04-43e1-fdb9-fb35a8fa0d6f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ HTML report generated successfully: fnb_evaluation_report_5.html\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<!DOCTYPE html>\n",
              "<html lang=\"en\">\n",
              "<head>\n",
              "    <meta charset=\"UTF-8\">\n",
              "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
              "    <title>F&B Image Evaluation Report</title>\n",
              "    <style>\n",
              "        body { font-family: sans-serif; margin: 20px; line-height: 1.6; }\n",
              "        .image-section { margin-bottom: 40px; border-bottom: 2px solid #eee; padding-bottom: 20px; }\n",
              "        .image-container img { max-width: 400px; max-height: 400px; border: 1px solid #ccc; margin-bottom: 15px; }\n",
              "        table { border-collapse: collapse; width: 100%; margin-top: 15px; font-size: 0.9em; }\n",
              "        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; vertical-align: top; }\n",
              "        th { background-color: #f2f2f2; }\n",
              "        tr:nth-child(even) { background-color: #f9f9f9; }\n",
              "        td:first-child { font-weight: bold; min-width: 150px; } /* Model name column */\n",
              "        .status-success { color: green; }\n",
              "        .status-error { color: red; font-weight: bold; }\n",
              "        .description-cell { white-space: pre-wrap; word-wrap: break-word; } /* Wrap long text */\n",
              "    </style>\n",
              "</head>\n",
              "<body>\n",
              "    <h1>F&B Image Evaluation Report</h1>\n",
              "    <p>Date Generated: 2025-04-23 21:38:50 UTC</p>\n",
              "\n",
              "    \n",
              "    <div class=\"image-section\">\n",
              "        <h2>Image ID: menu_0003</h2>\n",
              "        <p><strong>Category:</strong> Menu Displays</p>\n",
              "        <div class=\"image-container\">\n",
              "            \n",
              "            <img src=\"/content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu_0003.JPG\" alt=\"Image menu_0003\" onerror=\"this.alt='Image not found at /content/drive/MyDrive/AI Imagery Marketing Tool/Colab Notebook/dataset_image/Menu Displays/menu_0003.JPG'; this.style.border='1px solid red';\">\n",
              "        </div>\n",
              "\n",
              "        <table>\n",
              "            <thead>\n",
              "                <tr>\n",
              "                    <th>Model</th>\n",
              "                    <th>Status</th>\n",
              "                    <th>Total Tokens</th>\n",
              "                    <th>Est. Cost (USD)</th>\n",
              "                    <th>Primary Subject</th>\n",
              "                    <th>Composition/Framing</th>\n",
              "                    <th>Background/Environment</th>\n",
              "                    <th>Lighting/Color</th>\n",
              "                    <th>Texture/Materials</th>\n",
              "                    <th>Text/Branding</th>\n",
              "                    <th>Mood/Atmosphere</th>\n",
              "                    <th>Overall Style</th>\n",
              "                </tr>\n",
              "            </thead>\n",
              "            <tbody>\n",
              "                \n",
              "                <tr>\n",
              "                    <td>gemini-2.5-pro-exp-03-25</td>\n",
              "                    <td class=\"status-success\">Success</td>\n",
              "                    <td>3356</td>\n",
              "                    <td>0.000000</td>\n",
              "                    <td class=\"description-cell\">Two sandwiches featured prominently. The top sandwich is a &amp;#x27;Cheesy Smoked Beef Sandwich&amp;#x27; (芝芝熏牛三明治) served in a golden-brown, soft brioche-style bun, filled with layers of pink sliced smoked beef (pastrami), sautéed sliced mushrooms, white onions, and possibly melted cheese. The bottom sandwich is a &amp;#x27;Musang King Durian Tender Chicken Croissant&amp;#x27; (猫山王榴莲嫩鸡牛角), a golden-brown, flaky croissant filled with fluffy yellow scrambled eggs, pieces of tender chicken, and a creamy sauce (likely the durian salad dressing), with some herbs sprinkled on the eggs.</td>\n",
              "                    <td class=\"description-cell\">Overhead shot (top-down view). The two sandwiches are arranged diagonally across the frame, appearing to burst through the background paper. The composition is dynamic but relatively balanced. Framing is a medium shot, capturing the sandwiches and surrounding text elements clearly.</td>\n",
              "                    <td class=\"description-cell\">The background is a flat, light brown, textured paper surface resembling parchment or a craft paper bag. The sandwiches are presented as if tearing through ripped holes in this paper, with torn edges visible around them. A few loose, cooked mushroom slices are scattered near the top sandwich as foreground/midground elements. The depth of field is relatively shallow, keeping the sandwiches and immediate ripped paper edges sharp, while the flat background paper is slightly softer.</td>\n",
              "                    <td class=\"description-cell\">Bright, even studio lighting, likely positioned slightly above and in front of the subjects. Shadows are soft and minimal, primarily visible under the sandwiches and creating depth around the torn paper edges. The dominant color palette includes warm browns (bread, paper), golden yellow (croissant, eggs, cheese), pink (beef), white (onions, cheese), accented by blue and orange text elements. The overall color temperature is warm and inviting.</td>\n",
              "                    <td class=\"description-cell\">Visible textures include the glossy, golden crust of the brioche bun; the flaky, layered texture of the croissant; the soft, slightly wrinkled surface of the sliced beef; the smooth, possibly melted texture of cheese; the fluffy, moist appearance of the scrambled eggs; the fibrous texture of the cooked mushrooms; and the matte, slightly crumpled texture of the brown paper background. The text elements have a distressed, stamped texture.</td>\n",
              "                    <td class=\"description-cell\">Extensive text overlay typical of a promotional poster. Top features large, distressed blue block text &amp;quot;买一送一&amp;quot; (Buy One Get One Free) and large orange distressed text &amp;quot;灵感简餐&amp;quot; (Inspired Light Meal). Specific item names (&amp;quot;芝芝熏牛三明治&amp;quot;, &amp;quot;猫山王榴莲嫩鸡牛角&amp;quot;) and descriptions/ingredients are placed in distressed blue boxes near each sandwich using a mix of vertical and horizontal layouts. Promotional details (&amp;quot;10.26-10.28, 喜茶GO小程序下单&amp;quot;, &amp;quot;买一送一&amp;quot;, fine print) are at the bottom in smaller black sans-serif font. A price (&amp;quot;¥25/个&amp;quot;) is highlighted in a red-orange starburst shape. A small blue icon of a person drinking appears near the top right. The overall text style is bold, distressed, and promotional.</td>\n",
              "                    <td class=\"description-cell\">Energetic, appetizing, and promotional. The &amp;#x27;bursting through paper&amp;#x27; visual creates a dynamic and slightly rustic feel, while the food photography aims for deliciousness. It feels casual yet enticing.</td>\n",
              "                    <td class=\"description-cell\">Photorealistic food presentation combined with graphic design poster elements. The style uses clean studio lighting and a shallow depth of field to emphasize the food. The background and text employ a distressed, slightly rustic graphic style. Post-processing likely includes color enhancement to make the food look appealing and saturation adjustments to balance the food and graphic elements.</td>\n",
              "                </tr>\n",
              "                \n",
              "            </tbody>\n",
              "        </table>\n",
              "    </div>\n",
              "    \n",
              "\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H3D-kuFlApQ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e6d8264b6b64a8a8ef92d2431cbab33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86c9ba8318964c9e9a373501a79ad6be",
              "IPY_MODEL_37d1231d6e5e41c59c99016635145141",
              "IPY_MODEL_3dafe5112ad8475d916ba9c0ea4b517b"
            ],
            "layout": "IPY_MODEL_a055cbc607cd4cd2af99b14a84bd1af0"
          }
        },
        "86c9ba8318964c9e9a373501a79ad6be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587f948dab6f43e092ab64590db25af7",
            "placeholder": "​",
            "style": "IPY_MODEL_17f56e0f322f45939bf61aedfc3a00d1",
            "value": "Processing Images: 100%"
          }
        },
        "37d1231d6e5e41c59c99016635145141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd231bc478e24e2bade2d3ed12baed5b",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5072f60c47ba484ba16923bfcb29c257",
            "value": 24
          }
        },
        "3dafe5112ad8475d916ba9c0ea4b517b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69badbab25aa4150ba332764445d327c",
            "placeholder": "​",
            "style": "IPY_MODEL_a28daaf08cd44423946ff0ff231627a4",
            "value": " 24/24 [00:16&lt;00:00,  1.10s/it]"
          }
        },
        "a055cbc607cd4cd2af99b14a84bd1af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587f948dab6f43e092ab64590db25af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f56e0f322f45939bf61aedfc3a00d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd231bc478e24e2bade2d3ed12baed5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5072f60c47ba484ba16923bfcb29c257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69badbab25aa4150ba332764445d327c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28daaf08cd44423946ff0ff231627a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "453dc98d824c416d8f8921c08205e51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d068f318dd1b4f84b9908d2dd710672b",
              "IPY_MODEL_62e1628ef24a46feaed6a34247ed017f",
              "IPY_MODEL_3a6f40dd496a4ca495c98bcac8865f4c"
            ],
            "layout": "IPY_MODEL_0d3b73d7538443b0afb9c7d40adbe955"
          }
        },
        "d068f318dd1b4f84b9908d2dd710672b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d0a2eb5d3b474da809dd26a2ff85a2",
            "placeholder": "​",
            "style": "IPY_MODEL_b5cd74cc34b440dfbf0e9fb03cd1f737",
            "value": "  Models for menu_0003: 100%"
          }
        },
        "62e1628ef24a46feaed6a34247ed017f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1d223cd7224517ad2257ac30d56715",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b34432a82e04e6ba8674a67adbd0980",
            "value": 1
          }
        },
        "3a6f40dd496a4ca495c98bcac8865f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ebdc4fa9fe4d3b8051045d1b45e6bb",
            "placeholder": "​",
            "style": "IPY_MODEL_a41c4b879e96406398fec6dc0b594cf8",
            "value": " 1/1 [00:16&lt;00:00, 16.40s/it]"
          }
        },
        "0d3b73d7538443b0afb9c7d40adbe955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c5d0a2eb5d3b474da809dd26a2ff85a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cd74cc34b440dfbf0e9fb03cd1f737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1d223cd7224517ad2257ac30d56715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b34432a82e04e6ba8674a67adbd0980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85ebdc4fa9fe4d3b8051045d1b45e6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41c4b879e96406398fec6dc0b594cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}